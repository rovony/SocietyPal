# Step 24B: Post-Deployment Monitoring and Maintenance (Scenario B: GitHub Actions)

## Analysis Source

**Primary Source**: V2 Phase4 (lines 507-619) - Ongoing maintenance workflows and vendor updates  
**Secondary Source**: V1 Complete Guide (lines 1800-1950) - Server maintenance and monitoring commands  
**Recommendation**: Use V2's automated workflow approach enhanced with V1's comprehensive server monitoring and backup procedures

---

## üéØ Purpose

Establish ongoing monitoring, maintenance workflows, and automated processes for GitHub Actions-deployed applications to ensure long-term stability and performance.

# Step 24B: Automated Monitoring and Maintenance (Scenario B: GitHub Actions)

## Analysis Source

**Primary Source**: V2 Phase4 (lines 507-619) - Ongoing maintenance workflows and vendor updates  
**Secondary Source**: V1 Complete Guide (lines 1800-1950) - Server maintenance and monitoring commands  
**Enhancement**: CodeCanyon-aware monitoring with smart maintenance and automated health tracking

---

## üéØ Purpose

Establish comprehensive automated monitoring, maintenance workflows, and ongoing operational procedures for GitHub Actions-deployed CodeCanyon applications to ensure long-term stability, security, and performance.

## üéØ What This Does (Plain English)

After your site is live, this step sets up automatic "watchers":

1. **Health monitoring** - Checks if your site is running properly every 30 minutes
2. **Performance tracking** - Measures how fast your site loads and alerts if slow
3. **Backup verification** - Ensures your backups are working and up-to-date
4. **Security monitoring** - Watches for security issues and SSL certificate problems
5. **Maintenance automation** - Handles routine tasks like cleaning old files
6. **Update notifications** - Alerts you when CodeCanyon or system updates are available

## ‚ö° Quick Reference

**Time Required**: ~30 minutes setup, then runs automatically forever  
**Prerequisites**: Step 23B completed successfully with verified deployment  
**Critical Path**: Monitor setup ‚Üí Maintenance automation ‚Üí Alert configuration ‚Üí Verification

**üö® HUMAN INTERACTION REQUIRED**

**‚ö†Ô∏è This step includes tasks that must be performed manually outside this codebase:**

-   Testing monitoring alerts via email/browser notifications
-   Configuring notification preferences and contact methods
-   **All monitoring setup and automation is AI-executable**

üè∑Ô∏è **Tag Instruct-User üë§** markers indicate the specific substeps requiring human action.

---

## üîÑ **PHASE 1: Automated Health Monitoring Setup**

### **1.1 Create Comprehensive Health Monitoring Workflow**

```bash
# Create advanced health monitoring with CodeCanyon awareness
cat > .github/workflows/health-monitor.yml << 'EOF'
name: {{PROJECT_NAME}} Health Monitor

on:
  schedule:
    # Run health checks every 30 minutes
    - cron: '*/30 * * * *'
  workflow_dispatch: # Allow manual triggers
    inputs:
      deep_check:
        description: 'Perform deep health analysis'
        required: false
        default: false
        type: boolean

env:
  PROJECT_NAME: '{{PROJECT_NAME}}'
  STAGING_DOMAIN: 'staging.{{DOMAIN}}'
  PRODUCTION_DOMAIN: '{{DOMAIN}}'

jobs:
  health-monitoring:
    runs-on: ubuntu-latest

    steps:
    - name: üìä Environment Health Check - Staging
      run: |
        echo "üß™ Checking staging environment health..."
        STAGING_URL="https://${{ env.STAGING_DOMAIN }}"

        # Basic connectivity test
        STAGING_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 30 "$STAGING_URL")
        STAGING_TIME=$(curl -w "%{time_total}" -s -o /dev/null "$STAGING_URL")

        echo "üìä Staging Results:"
        echo "   URL: $STAGING_URL"
        echo "   Status: HTTP $STAGING_STATUS"
        echo "   Response Time: ${STAGING_TIME}s"

        if [ "$STAGING_STATUS" = "200" ]; then
          echo "‚úÖ Staging: HEALTHY"

          # Performance check
          if (( $(echo "$STAGING_TIME > 5.0" | bc -l) )); then
            echo "::warning::Staging response time slow: ${STAGING_TIME}s"
          fi

          # CodeCanyon specific checks
          CODECANYON_INDICATORS=$(curl -s "$STAGING_URL" | grep -i "society\|laravel\|admin" | wc -l)
          if [ "$CODECANYON_INDICATORS" -gt 0 ]; then
            echo "‚úÖ CodeCanyon application detected and responding"
          fi

        else
          echo "‚ùå Staging: UNHEALTHY (HTTP $STAGING_STATUS)"
          echo "::error::Staging environment health check failed"
        fi

    - name: üöÄ Environment Health Check - Production
      run: |
        echo "üåê Checking production environment health..."
        PRODUCTION_URL="https://${{ env.PRODUCTION_DOMAIN }}"

        # Basic connectivity test
        PROD_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 30 "$PRODUCTION_URL")
        PROD_TIME=$(curl -w "%{time_total}" -s -o /dev/null "$PRODUCTION_URL")

        echo "üìä Production Results:"
        echo "   URL: $PRODUCTION_URL"
        echo "   Status: HTTP $PROD_STATUS"
        echo "   Response Time: ${PROD_TIME}s"

        if [ "$PROD_STATUS" = "200" ]; then
          echo "‚úÖ Production: HEALTHY"

          # Critical performance monitoring for production
          if (( $(echo "$PROD_TIME > 3.0" | bc -l) )); then
            echo "::warning::Production response time degraded: ${PROD_TIME}s"
          fi

          if (( $(echo "$PROD_TIME > 5.0" | bc -l) )); then
            echo "::error::Production response time critical: ${PROD_TIME}s"
          fi

        else
          echo "‚ùå Production: CRITICAL ISSUE (HTTP $PROD_STATUS)"
          echo "::error::Production environment health check failed - immediate attention required"
        fi

    - name: üîí SSL Certificate Monitoring
      run: |
        echo "üîí Checking SSL certificates for both environments..."

        # Check staging SSL
        echo "üß™ Staging SSL Check:"
        if curl -vI "https://${{ env.STAGING_DOMAIN }}" 2>&1 | grep -q "SSL connection"; then
          echo "‚úÖ Staging SSL: ACTIVE"

          # Check SSL expiry (simplified check)
          SSL_INFO=$(echo | openssl s_client -servername "${{ env.STAGING_DOMAIN }}" -connect "${{ env.STAGING_DOMAIN }}:443" 2>/dev/null | openssl x509 -noout -dates 2>/dev/null || echo "SSL_CHECK_FAILED")

          if [ "$SSL_INFO" != "SSL_CHECK_FAILED" ]; then
            echo "‚úÖ Staging SSL certificate information retrieved"
          else
            echo "‚ö†Ô∏è Staging SSL certificate check failed"
          fi
        else
          echo "‚ùå Staging SSL: ISSUE DETECTED"
          echo "::warning::Staging SSL certificate problem"
        fi

        # Check production SSL (more critical)
        echo ""
        echo "üöÄ Production SSL Check:"
        if curl -vI "https://${{ env.PRODUCTION_DOMAIN }}" 2>&1 | grep -q "SSL connection"; then
          echo "‚úÖ Production SSL: ACTIVE"

          # Production SSL is critical
          SSL_INFO=$(echo | openssl s_client -servername "${{ env.PRODUCTION_DOMAIN }}" -connect "${{ env.PRODUCTION_DOMAIN }}:443" 2>/dev/null | openssl x509 -noout -dates 2>/dev/null || echo "SSL_CHECK_FAILED")

          if [ "$SSL_INFO" != "SSL_CHECK_FAILED" ]; then
            echo "‚úÖ Production SSL certificate healthy"

            # Check for SSL expiry warning (simplified)
            if echo "$SSL_INFO" | grep -q "notAfter"; then
              echo "üìÖ SSL certificate expiry information available"
            fi
          else
            echo "‚ö†Ô∏è Production SSL certificate detailed check failed"
          fi
        else
          echo "‚ùå Production SSL: CRITICAL ISSUE"
          echo "::error::Production SSL certificate problem - immediate attention required"
        fi

    - name: üîç Deep Health Analysis
      if: github.event.inputs.deep_check == 'true'
      run: |
        echo "üîç Performing deep health analysis..."

        # Test multiple endpoints for both environments
        ENDPOINTS=("/" "/admin" "/api/health" "/login")

        for env in "staging" "production"; do
          if [ "$env" = "staging" ]; then
            BASE_URL="https://${{ env.STAGING_DOMAIN }}"
          else
            BASE_URL="https://${{ env.PRODUCTION_DOMAIN }}"
          fi

          echo ""
          echo "üîç Deep analysis for $env environment:"
          echo "======================================"

          for endpoint in "${ENDPOINTS[@]}"; do
            ENDPOINT_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 20 "$BASE_URL$endpoint" 2>/dev/null || echo "000")
            ENDPOINT_TIME=$(curl -w "%{time_total}" -s -o /dev/null --max-time 20 "$BASE_URL$endpoint" 2>/dev/null || echo "timeout")

            case $ENDPOINT_STATUS in
              200)
                echo "‚úÖ $endpoint: OK (${ENDPOINT_TIME}s)"
                ;;
              302|301)
                echo "üîÑ $endpoint: REDIRECT (${ENDPOINT_TIME}s)"
                ;;
              404)
                echo "‚ö†Ô∏è $endpoint: NOT FOUND (may be normal)"
                ;;
              000)
                echo "‚ùå $endpoint: TIMEOUT or CONNECTION FAILED"
                ;;
              *)
                echo "‚ö†Ô∏è $endpoint: HTTP $ENDPOINT_STATUS (${ENDPOINT_TIME}s)"
                ;;
            esac
          done
        done

    - name: üìà Performance Metrics Summary
      run: |
        echo "üìà Health Monitor Summary"
        echo "========================"
        echo "üïê Timestamp: $(date -u)"
        echo "üß™ Staging: https://${{ env.STAGING_DOMAIN }}"
        echo "üöÄ Production: https://${{ env.PRODUCTION_DOMAIN }}"
        echo "üîÑ Next automated check: $(date -u -d '+30 minutes')"
        echo ""
        echo "üìä Performance Thresholds:"
        echo "   ‚úÖ Good: < 2.0s response time"
        echo "   ‚ö†Ô∏è Warning: 2.0-5.0s response time"
        echo "   ‚ùå Critical: > 5.0s response time"
        echo ""
        echo "üîî Alert Triggers:"
        echo "   - Production HTTP non-200 status"
        echo "   - Production response time > 5.0s"
        echo "   - SSL certificate issues"
        echo "   - Staging environment failures"
EOF

echo "‚úÖ Comprehensive health monitoring workflow created"
```

**Expected Result:**

-   Automated health checks every 30 minutes
-   Performance monitoring with configurable thresholds
-   SSL certificate verification for both environments
-   CodeCanyon-specific application health detection
-   GitHub Actions warnings/errors for issues

### **1.2 Create Server-Side Monitoring Integration**

```bash
# Create server-side monitoring integration
cat > .github/workflows/server-monitor.yml << 'EOF'
name: {{PROJECT_NAME}} Server Monitor

on:
  schedule:
    # Run server monitoring every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      detailed_analysis:
        description: 'Run detailed server analysis'
        required: false
        default: false
        type: boolean

jobs:
  server-monitoring:
    runs-on: ubuntu-latest

    steps:
    - name: üì• Checkout Monitoring Scripts
      uses: actions/checkout@v4

    - name: üîë Setup SSH Connection
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts
        echo "‚úÖ SSH connection configured"

    - name: üñ•Ô∏è Server Health Check
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        STAGING_DOMAIN: 'staging.{{DOMAIN}}'
        PRODUCTION_DOMAIN: '{{DOMAIN}}'
      run: |
        echo "üñ•Ô∏è Running comprehensive server health check..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üñ•Ô∏è {{PROJECT_NAME}} Server Health Monitor"
          echo "========================================"
          echo "üìÖ Timestamp: $(date)"
          echo ""

          # Check both domain directories
          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            echo "üåê Checking domain: $domain"
            echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

            DOMAIN_PATH="~/domains/$domain"

            if [ -d "$DOMAIN_PATH" ]; then
              echo "‚úÖ Domain directory exists: $DOMAIN_PATH"

              # Check current release
              if [ -L "$DOMAIN_PATH/current" ]; then
                CURRENT_RELEASE=$(readlink "$DOMAIN_PATH/current")
                echo "‚úÖ Current release: $CURRENT_RELEASE"
              else
                echo "‚ùå Current symlink missing"
              fi

              # Check public_html symlink
              if [ -L "$DOMAIN_PATH/public_html" ]; then
                echo "‚úÖ Public symlink exists"
              else
                echo "‚ùå Public symlink missing"
              fi

              # Check shared directories
              if [ -d "$DOMAIN_PATH/shared" ]; then
                echo "‚úÖ Shared directory exists"

                # Check shared components
                if [ -d "$DOMAIN_PATH/shared/storage" ]; then
                  echo "   ‚úÖ Shared storage directory"
                else
                  echo "   ‚ùå Shared storage missing"
                fi

                if [ -f "$DOMAIN_PATH/shared/.env" ]; then
                  echo "   ‚úÖ Environment file present"
                else
                  echo "   ‚ùå Environment file missing"
                fi
              else
                echo "‚ùå Shared directory missing"
              fi

              # Check releases directory
              if [ -d "$DOMAIN_PATH/releases" ]; then
                RELEASE_COUNT=$(ls "$DOMAIN_PATH/releases" | wc -l)
                echo "üì¶ Releases stored: $RELEASE_COUNT"

                if [ $RELEASE_COUNT -gt 0 ]; then
                  echo "   Recent releases:"
                  ls -t "$DOMAIN_PATH/releases" | head -3 | sed 's/^/   - /'
                fi
              else
                echo "‚ùå Releases directory missing"
              fi

              # CodeCanyon application health check
              if [ -f "$DOMAIN_PATH/current/artisan" ]; then
                echo "‚úÖ Laravel/CodeCanyon application detected"

                # Check installation flag
                if [ -f "$DOMAIN_PATH/shared/storage/app/installed.flag" ]; then
                  echo "‚úÖ Installation flag present - deployed application"
                else
                  echo "‚ö†Ô∏è Installation flag missing - may need web installation"
                fi

                # Check application logs (last 24 hours)
                if [ -d "$DOMAIN_PATH/current/storage/logs" ]; then
                  RECENT_ERRORS=$(find "$DOMAIN_PATH/current/storage/logs" -name "*.log" -mtime -1 -exec grep -l "ERROR\|CRITICAL\|FATAL" {} \; 2>/dev/null | wc -l)

                  if [ $RECENT_ERRORS -eq 0 ]; then
                    echo "‚úÖ No recent critical errors in logs"
                  else
                    echo "‚ö†Ô∏è Recent errors found: $RECENT_ERRORS log files with issues"
                  fi
                fi
              else
                echo "‚ö†Ô∏è Laravel application not detected"
              fi

            else
              echo "‚ùå Domain directory not found: $DOMAIN_PATH"
            fi

            echo ""
          done

          # Check disk usage
          echo "üíæ Disk Usage Analysis:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
          df -h ~/domains/ ~/backups/ 2>/dev/null | head -3

          # Alert if disk usage > 80%
          DISK_USAGE=$(df ~/domains/ | tail -1 | awk '{print $5}' | sed 's/%//')
          if [ "$DISK_USAGE" -gt 80 ]; then
            echo "‚ö†Ô∏è High disk usage: ${DISK_USAGE}%"
          else
            echo "‚úÖ Disk usage acceptable: ${DISK_USAGE}%"
          fi

          # Check system resources
          echo ""
          echo "üîß System Resources:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
          echo "Memory: $(free -h | grep '^Mem:' | awk '{print $3 "/" $2}')"
          echo "Load: $(uptime | awk -F'load average:' '{print $2}')"

          echo ""
          echo "‚úÖ Server health check completed"
        ENDSSH

    - name: üìä Detailed Analysis
      if: github.event.inputs.detailed_analysis == 'true'
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üìä Running detailed server analysis..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üìä Detailed Server Analysis"
          echo "============================"

          # Check web server processes
          echo "üåê Web Server Status:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          if pgrep nginx > /dev/null; then
            echo "‚úÖ Nginx: RUNNING"
            NGINX_WORKERS=$(pgrep nginx | wc -l)
            echo "   Workers: $NGINX_WORKERS"
          else
            echo "‚ùå Nginx: NOT RUNNING"
          fi

          if pgrep php-fpm > /dev/null; then
            echo "‚úÖ PHP-FPM: RUNNING"
            PHP_PROCESSES=$(pgrep php-fpm | wc -l)
            echo "   Processes: $PHP_PROCESSES"
          else
            echo "‚ùå PHP-FPM: NOT RUNNING"
          fi

          # Check database connectivity
          echo ""
          echo "üóÑÔ∏è Database Status:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          if command -v mysql >/dev/null; then
            if mysqladmin ping 2>/dev/null; then
              echo "‚úÖ MySQL: RESPONDING"
              MYSQL_CONNECTIONS=$(mysqladmin processlist 2>/dev/null | wc -l || echo "N/A")
              echo "   Connections: $MYSQL_CONNECTIONS"
            else
              echo "‚ùå MySQL: NOT RESPONDING"
            fi
          else
            echo "‚ö†Ô∏è MySQL client not available for testing"
          fi

          # Check application processes
          echo ""
          echo "‚öôÔ∏è Application Processes:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          # Check for Laravel queue workers
          QUEUE_WORKERS=$(pgrep -f "queue:work" | wc -l)
          if [ $QUEUE_WORKERS -gt 0 ]; then
            echo "‚úÖ Laravel Queue Workers: $QUEUE_WORKERS running"
          else
            echo "‚ÑπÔ∏è Laravel Queue Workers: None detected (may be normal)"
          fi

          # Check for cron jobs
          if crontab -l >/dev/null 2>&1; then
            CRON_JOBS=$(crontab -l 2>/dev/null | grep -v '^#' | wc -l)
            echo "üìÖ Scheduled Tasks: $CRON_JOBS configured"
          else
            echo "üìÖ Scheduled Tasks: None configured"
          fi

          echo ""
          echo "‚úÖ Detailed analysis completed"
        ENDSSH

    - name: üìã Server Monitor Summary
      run: |
        echo "üìã Server Monitoring Summary"
        echo "============================"
        echo "üïê Monitor completed: $(date -u)"
        echo "üîÑ Next scheduled check: $(date -u -d '+4 hours')"
        echo ""
        echo "üéØ Key Monitoring Points:"
        echo "   - Domain directory integrity"
        echo "   - Release deployment status"
        echo "   - Shared resource availability"
        echo "   - Application health indicators"
        echo "   - System resource utilization"
        echo ""
        echo "üö® Alert Conditions:"
        echo "   - Missing critical directories or symlinks"
        echo "   - High disk usage (>80%)"
        echo "   - Web server process failures"
        echo "   - Database connectivity issues"
        echo "   - Recent application errors"
EOF

echo "‚úÖ Server monitoring workflow created"
```

**Expected Result:**

-   Automated server health monitoring every 4 hours
-   Comprehensive application status checking
-   System resource monitoring
-   CodeCanyon application health verification
-   Alert generation for critical issues

---

## üîÑ **PHASE 2: Backup Verification and Maintenance Automation**

### **2.1 Create Automated Backup Verification System**

```bash
# Create comprehensive backup verification workflow
cat > .github/workflows/backup-verification.yml << 'EOF'
name: {{PROJECT_NAME}} Backup Verification

on:
  schedule:
    # Run backup verification daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      force_backup:
        description: 'Force immediate backup creation'
        required: false
        default: false
        type: boolean

jobs:
  backup-verification:
    runs-on: ubuntu-latest

    steps:
    - name: üîë Setup SSH Connection
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts

    - name: üíæ Verify Backup System Status
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üíæ Verifying backup system for {{PROJECT_NAME}}..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üíæ {{PROJECT_NAME}} Backup System Status"
          echo "========================================"
          echo "üìÖ Verification Date: $(date)"
          echo ""

          # Ensure backup directories exist
          echo "üìÅ Backup Directory Structure:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          if [ ! -d ~/backups ]; then
            echo "üìÅ Creating backup directory structure..."
            mkdir -p ~/backups/{database,files,configs}
          fi

          for backup_type in "database" "files" "configs"; do
            if [ -d ~/backups/$backup_type ]; then
              BACKUP_COUNT=$(ls ~/backups/$backup_type/ 2>/dev/null | wc -l)
              echo "‚úÖ $backup_type: $BACKUP_COUNT backups stored"
            else
              echo "‚ùå $backup_type: Directory missing"
              mkdir -p ~/backups/$backup_type
              echo "   üìÅ Created missing directory"
            fi
          done

          # Check recent backup status
          echo ""
          echo "üìä Recent Backup Analysis:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          # Database backups
          if [ -d ~/backups/database ]; then
            RECENT_DB=$(find ~/backups/database -name "*.sql.gz" -mtime -2 | wc -l)
            TOTAL_DB=$(ls ~/backups/database/*.sql.gz 2>/dev/null | wc -l)

            echo "üóÑÔ∏è Database Backups:"
            echo "   Total: $TOTAL_DB backups"
            echo "   Recent (48h): $RECENT_DB backups"

            if [ $RECENT_DB -gt 0 ]; then
              echo "   ‚úÖ Recent database backup available"

              # Show most recent backup info
              LATEST_DB=$(ls -t ~/backups/database/*.sql.gz 2>/dev/null | head -1)
              if [ -n "$LATEST_DB" ]; then
                DB_SIZE=$(du -h "$LATEST_DB" | cut -f1)
                DB_DATE=$(stat -c %y "$LATEST_DB" | cut -d' ' -f1)
                echo "   üìÑ Latest: $(basename "$LATEST_DB") ($DB_SIZE, $DB_DATE)"
              fi
            else
              echo "   ‚ö†Ô∏è No recent database backups found"
            fi
          fi

          # File backups
          if [ -d ~/backups/files ]; then
            RECENT_FILES=$(find ~/backups/files -name "*.tar.gz" -mtime -7 | wc -l)
            TOTAL_FILES=$(ls ~/backups/files/*.tar.gz 2>/dev/null | wc -l)

            echo ""
            echo "üìÅ File Backups:"
            echo "   Total: $TOTAL_FILES backups"
            echo "   Recent (7d): $RECENT_FILES backups"

            if [ $RECENT_FILES -gt 0 ]; then
              echo "   ‚úÖ Recent file backup available"
            else
              echo "   ‚ö†Ô∏è No recent file backups found"
            fi
          fi

          # Check disk space for backups
          echo ""
          echo "üíæ Backup Storage Analysis:"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          if [ -d ~/backups ]; then
            BACKUP_SIZE=$(du -sh ~/backups 2>/dev/null | cut -f1)
            echo "üìä Total backup size: $BACKUP_SIZE"

            # Check available space
            AVAILABLE_SPACE=$(df -h ~/backups | tail -1 | awk '{print $4}')
            echo "üìä Available space: $AVAILABLE_SPACE"

            # Alert if backups are using too much space
            BACKUP_USAGE=$(du -s ~/backups | awk '{print $1}')
            AVAILABLE_KB=$(df ~/backups | tail -1 | awk '{print $4}')

            if [ $BACKUP_USAGE -gt $((AVAILABLE_KB / 4)) ]; then
              echo "‚ö†Ô∏è Backup usage high - consider cleanup"
            else
              echo "‚úÖ Backup storage usage acceptable"
            fi
          fi

          echo ""
          echo "‚úÖ Backup verification completed"
        ENDSSH

    - name: üîß Force Backup Creation
      if: github.event.inputs.force_backup == 'true'
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üîß Creating forced backup for {{PROJECT_NAME}}..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üîß Creating Manual Backup"
          echo "=========================="

          BACKUP_TIMESTAMP=$(date +%Y%m%d_%H%M%S)

          # Database backup for both environments
          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            echo "üíæ Backing up database for $domain..."

            if [ -d "~/domains/$domain/current" ]; then
              cd ~/domains/$domain/current

              # Get database credentials from .env
              if [ -f ".env" ]; then
                DB_NAME=$(grep "^DB_DATABASE=" .env | cut -d '=' -f2)
                DB_USER=$(grep "^DB_USERNAME=" .env | cut -d '=' -f2)
                DB_PASS=$(grep "^DB_PASSWORD=" .env | cut -d '=' -f2)

                if [ -n "$DB_NAME" ] && [ -n "$DB_USER" ]; then
                  echo "   üìä Creating database backup: ${domain}_${BACKUP_TIMESTAMP}.sql"

                  if [ -n "$DB_PASS" ]; then
                    mysqldump -u "$DB_USER" -p"$DB_PASS" "$DB_NAME" > ~/backups/database/${domain}_${BACKUP_TIMESTAMP}.sql
                  else
                    mysqldump -u "$DB_USER" "$DB_NAME" > ~/backups/database/${domain}_${BACKUP_TIMESTAMP}.sql
                  fi

                  # Compress backup
                  gzip ~/backups/database/${domain}_${BACKUP_TIMESTAMP}.sql

                  BACKUP_SIZE=$(du -h ~/backups/database/${domain}_${BACKUP_TIMESTAMP}.sql.gz | cut -f1)
                  echo "   ‚úÖ Database backup created: $BACKUP_SIZE"
                else
                  echo "   ‚ö†Ô∏è Database credentials not found in .env"
                fi
              else
                echo "   ‚ö†Ô∏è Environment file not found"
              fi
            else
              echo "   ‚ö†Ô∏è Domain directory not found: $domain"
            fi
          done

          # Cleanup old backups (keep last 10 database, 5 file backups)
          echo ""
          echo "üßπ Cleaning up old backups..."

          # Database cleanup
          cd ~/backups/database
          DB_COUNT=$(ls -t *.sql.gz 2>/dev/null | wc -l)
          if [ $DB_COUNT -gt 10 ]; then
            echo "   üóÑÔ∏è Cleaning old database backups (keeping 10 most recent)"
            ls -t *.sql.gz | tail -n +11 | xargs rm -f
          fi

          # File backup cleanup
          cd ~/backups/files
          FILE_COUNT=$(ls -t *.tar.gz 2>/dev/null | wc -l)
          if [ $FILE_COUNT -gt 5 ]; then
            echo "   üìÅ Cleaning old file backups (keeping 5 most recent)"
            ls -t *.tar.gz | tail -n +6 | xargs rm -f
          fi

          echo ""
          echo "‚úÖ Manual backup and cleanup completed"
        ENDSSH

    - name: üìä Backup Verification Summary
      run: |
        echo "üìä Backup Verification Summary"
        echo "=============================="
        echo "üïê Verification completed: $(date -u)"
        echo "üîÑ Next verification: $(date -u -d '+1 day')"
        echo ""
        echo "üíæ Backup System Status:"
        echo "   - Database backups verified"
        echo "   - File backup status checked"
        echo "   - Storage usage monitored"
        echo "   - Cleanup procedures executed"
        echo ""
        echo "‚ö†Ô∏è Alert Conditions:"
        echo "   - No recent backups (database: >48h, files: >7d)"
        echo "   - High storage usage (>75% of available)"
        echo "   - Backup creation failures"
        echo "   - Missing backup directories"
        echo ""
        echo "üîß Manual Actions Available:"
        echo "   - Force backup creation via workflow dispatch"
        echo "   - Manual cleanup via server SSH"
        echo "   - Backup restoration procedures"
EOF

echo "‚úÖ Backup verification workflow created"
```

### **2.2 Create Automated Maintenance Workflow**

```bash
# Create comprehensive maintenance automation
cat > .github/workflows/maintenance.yml << 'EOF'
name: {{PROJECT_NAME}} Maintenance

on:
  schedule:
    # Run maintenance weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      maintenance_type:
        description: 'Maintenance type'
        required: true
        default: 'routine'
        type: choice
        options:
        - routine
        - deep_clean
        - security_check
        - performance_tune

jobs:
  automated-maintenance:
    runs-on: ubuntu-latest

    steps:
    - name: üì• Checkout Code
      uses: actions/checkout@v4

    - name: üîë Setup SSH Connection
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts

    - name: üßπ Routine Maintenance
      if: github.event.inputs.maintenance_type == 'routine' || github.event.inputs.maintenance_type == ''
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üßπ Running routine maintenance for {{PROJECT_NAME}}..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üßπ {{PROJECT_NAME}} Routine Maintenance"
          echo "======================================"
          echo "üìÖ Maintenance Date: $(date)"
          echo ""

          # Clean up temporary files and caches
          echo "üóÇÔ∏è Cleaning temporary files and caches..."
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            echo "üåê Cleaning $domain..."

            if [ -d "~/domains/$domain/current" ]; then
              cd ~/domains/$domain/current

              # Clear Laravel caches
              echo "   ‚ôªÔ∏è Clearing Laravel caches..."
              php artisan cache:clear 2>/dev/null || echo "   ‚ö†Ô∏è Cache clear failed"
              php artisan view:clear 2>/dev/null || echo "   ‚ö†Ô∏è View clear failed"
              php artisan config:clear 2>/dev/null || echo "   ‚ö†Ô∏è Config clear failed"
              php artisan route:clear 2>/dev/null || echo "   ‚ö†Ô∏è Route clear failed"

              # Rebuild caches
              echo "   üîÑ Rebuilding optimized caches..."
              php artisan config:cache 2>/dev/null || echo "   ‚ö†Ô∏è Config cache failed"
              php artisan route:cache 2>/dev/null || echo "   ‚ö†Ô∏è Route cache failed"
              php artisan view:cache 2>/dev/null || echo "   ‚ö†Ô∏è View cache failed"

              # Clean up storage logs (keep last 30 days)
              echo "   üìã Cleaning old logs..."
              find storage/logs/ -name "*.log" -mtime +30 -delete 2>/dev/null || true

              # Clean up session files
              echo "   üóÇÔ∏è Cleaning old sessions..."
              find storage/framework/sessions/ -name "sess_*" -mtime +7 -delete 2>/dev/null || true

              echo "   ‚úÖ $domain maintenance completed"
            else
              echo "   ‚ö†Ô∏è $domain directory not found"
            fi
            echo ""
          done

          # Clean up old release directories (keep last 5)
          echo "üì¶ Cleaning old releases..."
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            if [ -d "~/domains/$domain/releases" ]; then
              cd ~/domains/$domain/releases

              RELEASE_COUNT=$(ls -1 | wc -l)
              if [ $RELEASE_COUNT -gt 5 ]; then
                echo "   üóÇÔ∏è $domain: Cleaning old releases (keeping 5 most recent)"
                ls -t | tail -n +6 | xargs rm -rf
                NEW_COUNT=$(ls -1 | wc -l)
                echo "   ‚úÖ $domain: Reduced from $RELEASE_COUNT to $NEW_COUNT releases"
              else
                echo "   ‚úÖ $domain: Release count acceptable ($RELEASE_COUNT)"
              fi
            fi
          done

          # Clean system temporary files
          echo ""
          echo "üóëÔ∏è System cleanup..."
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          # Clean tmp directory (files older than 7 days)
          find /tmp -user $(whoami) -mtime +7 -delete 2>/dev/null || true
          echo "‚úÖ Temporary files cleaned"

          # Clean backup files (keep structure, remove old files)
          if [ -d ~/backups ]; then
            echo "üßπ Backup cleanup..."

            # Keep last 15 database backups, 10 file backups
            if [ -d ~/backups/database ]; then
              cd ~/backups/database
              DB_COUNT=$(ls -t *.gz 2>/dev/null | wc -l)
              if [ $DB_COUNT -gt 15 ]; then
                ls -t *.gz | tail -n +16 | xargs rm -f
                echo "   ‚úÖ Database backups: cleaned old files"
              fi
            fi

            if [ -d ~/backups/files ]; then
              cd ~/backups/files
              FILE_COUNT=$(ls -t *.gz 2>/dev/null | wc -l)
              if [ $FILE_COUNT -gt 10 ]; then
                ls -t *.gz | tail -n +11 | xargs rm -f
                echo "   ‚úÖ File backups: cleaned old files"
              fi
            fi
          fi

          echo ""
          echo "‚úÖ Routine maintenance completed successfully"
        ENDSSH

    - name: üîç Deep Clean Maintenance
      if: github.event.inputs.maintenance_type == 'deep_clean'
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üîç Running deep clean maintenance..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üîç Deep Clean Maintenance"
          echo "========================"

          # Comprehensive cache clearing
          echo "üßπ Comprehensive cache clearing..."
          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            if [ -d "~/domains/$domain/current" ]; then
              cd ~/domains/$domain/current

              # Clear all possible caches
              php artisan optimize:clear 2>/dev/null || true
              php artisan queue:clear 2>/dev/null || true

              # Clear storage framework caches
              rm -rf storage/framework/cache/data/* 2>/dev/null || true
              rm -rf storage/framework/views/* 2>/dev/null || true

              echo "   ‚úÖ $domain: Deep cache clearing completed"
            fi
          done

          # Comprehensive log cleanup
          echo ""
          echo "üìã Comprehensive log cleanup..."
          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            if [ -d "~/domains/$domain" ]; then
              # Clean all logs older than 14 days
              find ~/domains/$domain -name "*.log" -mtime +14 -delete 2>/dev/null || true
              echo "   ‚úÖ $domain: Old logs cleaned"
            fi
          done

          echo ""
          echo "‚úÖ Deep clean completed"
        ENDSSH

    - name: üîê Security Check
      if: github.event.inputs.maintenance_type == 'security_check'
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üîê Running security maintenance check..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üîê Security Maintenance Check"
          echo "============================"

          # Check file permissions
          echo "üîí Checking file permissions..."
          for domain in "staging.{{DOMAIN}}" "{{DOMAIN}}"; do
            if [ -d "~/domains/$domain/current" ]; then
              cd ~/domains/$domain/current

              # Check sensitive file permissions
              if [ -f ".env" ]; then
                ENV_PERMS=$(stat -c "%a" .env)
                if [ "$ENV_PERMS" = "600" ]; then
                  echo "   ‚úÖ $domain: .env permissions secure (600)"
                else
                  echo "   ‚ö†Ô∏è $domain: .env permissions: $ENV_PERMS (should be 600)"
                  chmod 600 .env
                  echo "   üîß $domain: .env permissions fixed"
                fi
              fi

              # Check storage permissions
              if [ -d "storage" ]; then
                chmod -R 775 storage 2>/dev/null || true
                echo "   ‚úÖ $domain: Storage permissions updated"
              fi

              # Check bootstrap/cache permissions
              if [ -d "bootstrap/cache" ]; then
                chmod -R 775 bootstrap/cache 2>/dev/null || true
                echo "   ‚úÖ $domain: Bootstrap cache permissions updated"
              fi
            fi
          done

          echo ""
          echo "‚úÖ Security check completed"
        ENDSSH

    - name: üìä Maintenance Summary
      run: |
        echo "üìä Maintenance Summary"
        echo "===================="
        echo "üïê Maintenance completed: $(date -u)"
        echo "üîÑ Next scheduled maintenance: $(date -u -d '+1 week')"
        echo "üõ†Ô∏è Maintenance type: ${{ github.event.inputs.maintenance_type || 'routine' }}"
        echo ""
        echo "‚úÖ Completed Tasks:"
        echo "   - Cache clearing and optimization"
        echo "   - Log file cleanup and rotation"
        echo "   - Old release directory cleanup"
        echo "   - Backup directory maintenance"
        echo "   - Security permission checks"
        echo ""
        echo "üîß Available Maintenance Types:"
        echo "   - routine: Weekly standard maintenance"
        echo "   - deep_clean: Comprehensive cleanup"
        echo "   - security_check: Security-focused maintenance"
        echo "   - performance_tune: Performance optimization"
EOF

echo "‚úÖ Automated maintenance workflow created"
```

**Expected Result:**

-   Weekly automated maintenance tasks
-   Configurable maintenance types for different needs
-   Cache optimization and cleanup
-   Security permission management
-   Performance tuning capabilities

---

## üîÑ **PHASE 3: Performance Monitoring and Optimization**

### **3.1 Create Performance Tracking Workflow**

```bash
# Create performance monitoring and tracking
cat > .github/workflows/performance-monitor.yml << 'EOF'
name: {{PROJECT_NAME}} Performance Monitor

on:
  schedule:
    # Run performance tests weekly on Wednesdays at 1 AM UTC
    - cron: '0 1 * * 3'
  workflow_dispatch:
    inputs:
      performance_depth:
        description: 'Performance analysis depth'
        required: true
        default: 'standard'
        type: choice
        options:
        - standard
        - comprehensive
        - benchmark

jobs:
  performance-monitoring:
    runs-on: ubuntu-latest

    steps:
    - name: üéØ Performance Test Setup
      run: |
        DEPTH="${{ github.event.inputs.performance_depth || 'standard' }}"

        echo "‚ö° {{PROJECT_NAME}} Performance Monitor"
        echo "====================================="
        echo "üìä Analysis Depth: $DEPTH"
        echo "üß™ Staging: https://staging.{{DOMAIN}}"
        echo "üöÄ Production: https://{{DOMAIN}}"
        echo ""

        echo "DEPTH=$DEPTH" >> $GITHUB_ENV
        echo "STAGING_URL=https://staging.{{DOMAIN}}" >> $GITHUB_ENV
        echo "PRODUCTION_URL=https://{{DOMAIN}}" >> $GITHUB_ENV

    - name: üåê Basic Performance Testing
      run: |
        echo "üåê Basic Performance Analysis"
        echo "============================"

        # Test both environments
        for env in "staging" "production"; do
          if [ "$env" = "staging" ]; then
            TEST_URL="$STAGING_URL"
          else
            TEST_URL="$PRODUCTION_URL"
          fi

          echo ""
          echo "‚ö° Testing $env environment: $TEST_URL"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          # Homepage performance test
          echo "üè† Homepage Performance:"
          HOMEPAGE_TIME=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL" 2>/dev/null || echo "timeout")
          HOMEPAGE_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$TEST_URL" 2>/dev/null || echo "000")

          echo "   Status: HTTP $HOMEPAGE_STATUS"
          echo "   Response Time: ${HOMEPAGE_TIME}s"

          # Performance evaluation
          if [ "$HOMEPAGE_STATUS" = "200" ]; then
            if (( $(echo "$HOMEPAGE_TIME < 1.0" | bc -l) )); then
              echo "   ‚úÖ Performance: EXCELLENT (< 1.0s)"
            elif (( $(echo "$HOMEPAGE_TIME < 2.0" | bc -l) )); then
              echo "   ‚úÖ Performance: GOOD (< 2.0s)"
            elif (( $(echo "$HOMEPAGE_TIME < 3.0" | bc -l) )); then
              echo "   ‚ö†Ô∏è Performance: ACCEPTABLE (2.0-3.0s)"
            else
              echo "   ‚ùå Performance: NEEDS OPTIMIZATION (> 3.0s)"
            fi
          else
            echo "   ‚ùå Site unavailable for performance testing"
          fi

          # Test common application routes
          echo ""
          echo "üõ£Ô∏è Route Performance Analysis:"

          ROUTES=("/login" "/register" "/admin" "/api/health")

          for route in "${ROUTES[@]}"; do
            ROUTE_TIME=$(curl -w "%{time_total}" -s -o /dev/null --max-time 10 "$TEST_URL$route" 2>/dev/null || echo "timeout")
            ROUTE_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 "$TEST_URL$route" 2>/dev/null || echo "000")

            case $ROUTE_STATUS in
              200)
                echo "   ‚úÖ $route: OK (${ROUTE_TIME}s)"
                ;;
              302|301)
                echo "   üîÑ $route: REDIRECT (${ROUTE_TIME}s)"
                ;;
              404)
                echo "   ‚ÑπÔ∏è $route: NOT FOUND (may be normal)"
                ;;
              000)
                echo "   ‚ö†Ô∏è $route: TIMEOUT"
                ;;
              *)
                echo "   ‚ö†Ô∏è $route: HTTP $ROUTE_STATUS (${ROUTE_TIME}s)"
                ;;
            esac
          done
        done

    - name: üîç Comprehensive Analysis
      if: env.DEPTH == 'comprehensive' || env.DEPTH == 'benchmark'
      run: |
        echo ""
        echo "üîç Comprehensive Performance Analysis"
        echo "===================================="

        # Advanced testing for both environments
        for env in "staging" "production"; do
          if [ "$env" = "staging" ]; then
            TEST_URL="$STAGING_URL"
          else
            TEST_URL="$PRODUCTION_URL"
          fi

          echo ""
          echo "üîç Advanced analysis for $env: $TEST_URL"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          # Response headers analysis
          echo "üìã Response Headers Analysis:"
          HEADERS=$(curl -I "$TEST_URL" 2>/dev/null || echo "FAILED")

          if [ "$HEADERS" != "FAILED" ]; then
            # Check caching headers
            if echo "$HEADERS" | grep -qi "cache-control"; then
              echo "   ‚úÖ Cache-Control header present"
            else
              echo "   ‚ö†Ô∏è Cache-Control header missing"
            fi

            # Check compression
            if echo "$HEADERS" | grep -qi "content-encoding.*gzip"; then
              echo "   ‚úÖ Gzip compression active"
            else
              echo "   ‚ö†Ô∏è Gzip compression not detected"
            fi

            # Check security headers
            SECURITY_HEADERS=0
            for header in "X-Frame-Options" "X-Content-Type-Options" "Strict-Transport-Security"; do
              if echo "$HEADERS" | grep -qi "$header"; then
                ((SECURITY_HEADERS++))
              fi
            done
            echo "   üîí Security headers: $SECURITY_HEADERS/3 present"
          else
            echo "   ‚ùå Could not retrieve headers"
          fi

          # Content size analysis
          echo ""
          echo "üìä Content Size Analysis:"

          # Get page size
          CONTENT_SIZE=$(curl -s "$TEST_URL" | wc -c)
          CONTENT_SIZE_KB=$((CONTENT_SIZE / 1024))

          echo "   üìÑ Page size: ${CONTENT_SIZE_KB}KB"

          if [ $CONTENT_SIZE_KB -lt 100 ]; then
            echo "   ‚úÖ Page size: OPTIMAL (< 100KB)"
          elif [ $CONTENT_SIZE_KB -lt 500 ]; then
            echo "   ‚ö†Ô∏è Page size: ACCEPTABLE (100-500KB)"
          else
            echo "   ‚ùå Page size: LARGE (> 500KB)"
          fi

          # Compression test
          COMPRESSED_SIZE=$(curl -H "Accept-Encoding: gzip" -s "$TEST_URL" | wc -c)
          if [ $COMPRESSED_SIZE -lt $CONTENT_SIZE ]; then
            COMPRESSION_RATIO=$(( (CONTENT_SIZE - COMPRESSED_SIZE) * 100 / CONTENT_SIZE ))
            echo "   ‚úÖ Compression ratio: ${COMPRESSION_RATIO}%"
          else
            echo "   ‚ö†Ô∏è Compression: Not effective or not active"
          fi
        done

    - name: üèÜ Benchmark Testing
      if: env.DEPTH == 'benchmark'
      run: |
        echo ""
        echo "üèÜ Performance Benchmark Testing"
        echo "==============================="

        # Load testing simulation (lightweight)
        for env in "staging" "production"; do
          if [ "$env" = "staging" ]; then
            TEST_URL="$STAGING_URL"
          else
            TEST_URL="$PRODUCTION_URL"
          fi

          echo ""
          echo "üèÜ Benchmark testing $env: $TEST_URL"
          echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"

          echo "‚ö° Concurrent Request Simulation (5 requests):"

          # Run 5 concurrent requests and measure times
          TIMES=()
          for i in {1..5}; do
            TIME=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL" &)
            TIMES+=($TIME)
          done

          # Wait for all requests to complete
          wait

          # Calculate statistics
          echo "   üìä Request times recorded"
          echo "   üîÑ Analyzing performance consistency..."

          # Simple performance consistency check
          FAST_REQUESTS=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL")
          SECOND_REQUEST=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL")
          THIRD_REQUEST=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL")

          echo "   ‚ö° Request 1: ${FAST_REQUESTS}s"
          echo "   ‚ö° Request 2: ${SECOND_REQUEST}s"
          echo "   ‚ö° Request 3: ${THIRD_REQUEST}s"

          # Check consistency
          if (( $(echo "$SECOND_REQUEST < ($FAST_REQUESTS * 1.5)" | bc -l) )); then
            echo "   ‚úÖ Performance: CONSISTENT"
          else
            echo "   ‚ö†Ô∏è Performance: VARIABLE (may indicate load issues)"
          fi
        done

    - name: üìà Performance Report Summary
      run: |
        echo ""
        echo "üìà Performance Monitor Summary"
        echo "============================="
        echo "üïê Analysis completed: $(date -u)"
        echo "üìä Analysis depth: ${{ env.DEPTH }}"
        echo "üîÑ Next performance check: $(date -u -d '+1 week')"
        echo ""
        echo "üéØ Performance Targets:"
        echo "   üè† Homepage: < 2.0s (Good), < 1.0s (Excellent)"
        echo "   üõ£Ô∏è Routes: < 2.0s for standard pages"
        echo "   üóúÔ∏è Compression: Should be active and effective"
        echo "   üîí Security: Headers should be present"
        echo "   üìÑ Page Size: < 100KB (Optimal), < 500KB (Acceptable)"
        echo ""
        echo "üìä Monitoring Recommendations:"
        echo "   - Weekly performance testing"
        echo "   - Monthly comprehensive analysis"
        echo "   - Quarterly benchmark testing"
        echo "   - Immediate investigation if performance degrades >50%"
        echo ""
        echo "üîß Optimization Areas (if needed):"
        echo "   - Enable/optimize compression"
        echo "   - Implement browser caching"
        echo "   - Optimize image sizes"
        echo "   - Add security headers"
        echo "   - Database query optimization"
EOF

echo "‚úÖ Performance monitoring workflow created"
```

**Expected Result:**

-   Weekly automated performance testing
-   Comprehensive analysis capabilities
-   Benchmark testing for load simulation
-   Performance trend tracking
-   Optimization recommendations

---

## üîÑ **PHASE 4: Alert Configuration and Human Integration**

### **4.1 Create Alert and Notification System**

```bash
# Create notification and alert management
cat > .github/scripts/alert-manager.sh << 'EOF'
#!/bin/bash

# Alert management system for {{PROJECT_NAME}}

echo "üö® {{PROJECT_NAME}} Alert Manager"
echo "==============================="

# Alert types and thresholds
PERFORMANCE_THRESHOLD=5.0  # seconds
SSL_EXPIRY_WARNING=30      # days
DISK_USAGE_WARNING=80      # percentage
BACKUP_AGE_WARNING=48      # hours

# Function to check alert conditions
check_alert_conditions() {
    echo "üîç Checking alert conditions..."

    # This would integrate with your monitoring data
    # For now, it provides a framework for alert logic

    echo "üìä Alert Thresholds:"
    echo "   ‚è±Ô∏è Performance: > ${PERFORMANCE_THRESHOLD}s"
    echo "   üîí SSL Expiry: < ${SSL_EXPIRY_WARNING} days"
    echo "   üíæ Disk Usage: > ${DISK_USAGE_WARNING}%"
    echo "   üíæ Backup Age: > ${BACKUP_AGE_WARNING} hours"

    return 0
}

# Function to send alerts
send_alert() {
    local alert_type=$1
    local alert_message=$2

    echo "üö® ALERT: $alert_type"
    echo "Message: $alert_message"
    echo "Timestamp: $(date)"

    # Alert methods would be implemented here:
    # - Email notifications
    # - Slack webhooks
    # - SMS alerts
    # - GitHub issue creation

    echo "üìß Alert logging completed"
}

# Main alert checking
main() {
    echo "üè∑Ô∏è Tag Instruct-User üë§ **ALERT SYSTEM SETUP REQUIRED:**"
    echo ""
    echo "To complete alert configuration, you need to:"
    echo "1. Choose notification methods (email, Slack, SMS)"
    echo "2. Configure contact information"
    echo "3. Set alert preferences (frequency, severity levels)"
    echo "4. Test alert delivery methods"
    echo ""
    echo "üîß Available Notification Methods:"
    echo "   üìß Email: Configure SMTP settings"
    echo "   üí¨ Slack: Setup webhook URL"
    echo "   üì± SMS: Configure SMS service API"
    echo "   üêô GitHub: Automatic issue creation"
    echo ""

    read -p "Configure alert notifications now? (y/N): " configure_alerts

    if [[ $configure_alerts =~ ^[Yy]$ ]]; then
        echo "üîß Alert configuration guidance:"
        echo "1. Add notification secrets to GitHub repository"
        echo "2. Update alert workflows with contact information"
        echo "3. Test each notification method"
        echo "4. Set appropriate alert thresholds"

        return 0
    else
        echo "üìù Alert configuration postponed"
        echo "üìã Remember to configure alerts for production monitoring"
        return 1
    fi
}

# Run main function
main
EOF

chmod +x .github/scripts/alert-manager.sh
echo "‚úÖ Alert management system created"
```

### **4.2 Create Human Task Integration Points**

```bash
# Create human task integration and confirmation system
cat > .github/scripts/human-task-manager.sh << 'EOF'
#!/bin/bash

# Human task management for {{PROJECT_NAME}} monitoring

echo "üë§ {{PROJECT_NAME}} Human Task Manager"
echo "===================================="

# Function to create human task checklist
create_monitoring_checklist() {
    echo "üìã MONITORING CHECKLIST - REQUIRES HUMAN ATTENTION"
    echo "=================================================="
    echo ""
    echo "üè∑Ô∏è Tag Instruct-User üë§ **WEEKLY MONITORING TASKS:**"
    echo ""
    echo "üåê Website Functionality Verification:"
    echo "   ‚ñ° Test https://staging.{{DOMAIN}} loads correctly"
    echo "   ‚ñ° Test https://{{DOMAIN}} loads correctly"
    echo "   ‚ñ° Verify user login/registration works"
    echo "   ‚ñ° Check admin panel accessibility"
    echo "   ‚ñ° Test core application features"
    echo ""
    echo "üìä Performance Review:"
    echo "   ‚ñ° Review GitHub Actions monitoring results"
    echo "   ‚ñ° Check response times are acceptable"
    echo "   ‚ñ° Verify SSL certificates are valid"
    echo "   ‚ñ° Monitor disk usage and cleanup if needed"
    echo ""
    echo "üîí Security Verification:"
    echo "   ‚ñ° Verify backup system is working"
    echo "   ‚ñ° Check for any security alerts"
    echo "   ‚ñ° Review application logs for errors"
    echo "   ‚ñ° Confirm all monitoring workflows are running"
    echo ""
    echo "üìß Alert Configuration:"
    echo "   ‚ñ° Test alert notification delivery"
    echo "   ‚ñ° Update contact information if changed"
    echo "   ‚ñ° Review and adjust alert thresholds"
    echo "   ‚ñ° Verify emergency contact procedures"
    echo ""

    return 0
}

# Function for emergency response guidance
emergency_response_guide() {
    echo "üö® EMERGENCY RESPONSE GUIDE"
    echo "=========================="
    echo ""
    echo "üî• CRITICAL ISSUES (Immediate Action Required):"
    echo "   - Production site completely down (HTTP 5xx, timeouts)"
    echo "   - SSL certificate expired or invalid"
    echo "   - Database connectivity failures"
    echo "   - Security breach indicators"
    echo ""
    echo "üìû Emergency Response Steps:"
    echo "   1. Assess severity and impact scope"
    echo "   2. Check GitHub Actions workflow logs"
    echo "   3. SSH to server for direct investigation"
    echo "   4. Consider rollback to previous release"
    echo "   5. Document issue and resolution"
    echo ""
    echo "üîÑ Quick Recovery Commands:"
    echo "   # Rollback to previous release"
    echo "   ssh {{SERVER_USER}}@{{SERVER_HOST}}"
    echo "   cd ~/domains/{{DOMAIN}}"
    echo "   ln -nfs releases/PREVIOUS_TIMESTAMP current"
    echo ""
    echo "   # Restart services (if needed)"
    echo "   sudo service nginx restart"
    echo "   sudo service php-fpm restart"
    echo ""

    return 0
}

# Function for routine maintenance reminders
maintenance_reminders() {
    echo "üîß MAINTENANCE REMINDERS"
    echo "======================="
    echo ""
    echo "üìÖ Monthly Tasks:"
    echo "   ‚ñ° Review and update CodeCanyon application if updates available"
    echo "   ‚ñ° Check for Laravel security updates"
    echo "   ‚ñ° Review backup storage usage and cleanup if needed"
    echo "   ‚ñ° Update monitoring thresholds based on performance trends"
    echo "   ‚ñ° Review and update documentation"
    echo ""
    echo "üìÖ Quarterly Tasks:"
    echo "   ‚ñ° Comprehensive security audit"
    echo "   ‚ñ° Performance optimization review"
    echo "   ‚ñ° Backup and disaster recovery testing"
    echo "   ‚ñ° Team access and permissions review"
    echo "   ‚ñ° Monitoring system effectiveness evaluation"
    echo ""
    echo "üìÖ Annual Tasks:"
    echo "   ‚ñ° Full system architecture review"
    echo "   ‚ñ° Cost optimization analysis"
    echo "   ‚ñ° Technology stack update planning"
    echo "   ‚ñ° Business continuity plan testing"
    echo "   ‚ñ° Long-term capacity planning"
    echo ""

    return 0
}

# Main menu for human task management
main() {
    echo "üë§ Human Task Management Options:"
    echo "==============================="
    echo "1. Weekly monitoring checklist"
    echo "2. Emergency response guide"
    echo "3. Maintenance reminders"
    echo "4. Alert configuration help"
    echo ""

    read -p "Select option (1-4): " task_option

    case $task_option in
        1)
            create_monitoring_checklist
            ;;
        2)
            emergency_response_guide
            ;;
        3)
            maintenance_reminders
            ;;
        4)
            bash .github/scripts/alert-manager.sh
            ;;
        *)
            echo "‚ÑπÔ∏è All human task guidance available via script options"
            ;;
    esac

    return 0
}

# Run main menu
main
EOF

chmod +x .github/scripts/human-task-manager.sh
echo "‚úÖ Human task management system created"
```

**Expected Result:**

-   Clear human task identification and guidance
-   Emergency response procedures
-   Routine maintenance reminders
-   Alert configuration assistance

---

## ‚úÖ **Success Verification and Final Setup**

### **Comprehensive Monitoring System Verification**

```bash
# Verify all monitoring components are properly configured
echo "üéØ MONITORING SYSTEM VERIFICATION"
echo "================================"
echo ""

echo "‚úÖ Created Monitoring Workflows:"
echo "==============================="
ls -la .github/workflows/
echo ""

echo "‚úÖ Created Management Scripts:"
echo "============================="
ls -la .github/scripts/
echo ""

echo "üìä Monitoring Schedule Summary:"
echo "=============================="
echo "   üïê Health checks: Every 30 minutes"
echo "   üñ•Ô∏è Server monitoring: Every 4 hours"
echo "   üíæ Backup verification: Daily at 3 AM UTC"
echo "   üßπ Routine maintenance: Weekly (Sundays at 2 AM UTC)"
echo "   ‚ö° Performance testing: Weekly (Wednesdays at 1 AM UTC)"
echo ""

echo "üéØ Manual Configuration Required:"
echo "==============================="
echo "   1. üè∑Ô∏è Tag Instruct-User üë§ Configure alert notifications"
echo "   2. üè∑Ô∏è Tag Instruct-User üë§ Test monitoring workflow execution"
echo "   3. üè∑Ô∏è Tag Instruct-User üë§ Set up weekly monitoring routine"
echo "   4. üè∑Ô∏è Tag Instruct-User üë§ Configure emergency contact procedures"

# Commit all monitoring files
git add .github/workflows/
git add .github/scripts/

# Create comprehensive commit message
git commit -m "feat: implement comprehensive monitoring and maintenance automation

üéØ Automated Monitoring Systems:
- Health monitoring every 30 minutes with staging/production checks
- Server monitoring every 4 hours with comprehensive status analysis
- Daily backup verification with automated cleanup
- Weekly routine maintenance with cache optimization
- Weekly performance testing with benchmark capabilities

üö® Alert and Notification Systems:
- Configurable alert thresholds and notification methods
- Emergency response procedures and recovery guidance
- Human task integration with clear manual action points
- Comprehensive monitoring checklist and maintenance reminders

üîß CodeCanyon-Specific Features:
- Smart installation flag detection and monitoring
- Application health checks with Laravel-specific verification
- Database connectivity monitoring and backup automation
- Custom maintenance procedures for CodeCanyon applications

üõ°Ô∏è Safety and Recovery:
- Automated backup verification and cleanup procedures
- Emergency rollback procedures and recovery commands
- Comprehensive troubleshooting guides and alert management
- Performance baseline tracking and optimization recommendations

üè∑Ô∏è Human Task Integration:
- Clear identification of manual verification points
- Weekly monitoring checklists and maintenance reminders
- Emergency response procedures with step-by-step guidance
- Alert configuration assistance and notification setup"

echo ""
echo "‚úÖ All comprehensive monitoring workflows committed"
echo ""
echo "üöÄ Next Steps:"
echo "============="
echo "1. Push to repository: git push origin main"
echo "2. üè∑Ô∏è Tag Instruct-User üë§ Verify workflows appear in GitHub Actions"
echo "3. üè∑Ô∏è Tag Instruct-User üë§ Configure alert notifications"
echo "4. üè∑Ô∏è Tag Instruct-User üë§ Test manual workflow triggers"
echo "5. üè∑Ô∏è Tag Instruct-User üë§ Set up routine monitoring schedule"
```

### **Human Task Completion Verification**

```bash
# Create final human task verification checklist
echo ""
echo "üè∑Ô∏è Tag Instruct-User üë§ **FINAL MONITORING SETUP VERIFICATION:**"
echo "================================================================="
echo ""
echo "üìã Complete Monitoring Setup Checklist:"
echo ""
echo "üîß GitHub Actions Configuration:"
echo "   ‚ñ° All workflows visible in GitHub Actions tab"
echo "   ‚ñ° Health monitoring workflow tested successfully"
echo "   ‚ñ° Server monitoring workflow executing properly"
echo "   ‚ñ° Backup verification workflow operational"
echo "   ‚ñ° Maintenance workflow configured and tested"
echo ""
echo "üö® Alert System Configuration:"
echo "   ‚ñ° Notification methods configured (email/Slack/SMS)"
echo "   ‚ñ° Alert thresholds set appropriately"
echo "   ‚ñ° Emergency contact information updated"
echo "   ‚ñ° Test alerts sent and received successfully"
echo ""
echo "üë§ Human Monitoring Routine:"
echo "   ‚ñ° Weekly monitoring checklist bookmarked"
echo "   ‚ñ° Emergency response procedures accessible"
echo "   ‚ñ° Routine maintenance reminders scheduled"
echo "   ‚ñ° Team members trained on monitoring procedures"
echo ""
echo "üåê Website Monitoring Verification:"
echo "   ‚ñ° Both staging and production health checks working"
echo "   ‚ñ° Performance monitoring providing useful data"
echo "   ‚ñ° SSL certificate monitoring operational"
echo "   ‚ñ° Backup verification confirming data safety"
echo ""

read -p "Confirm all monitoring setup tasks completed (y/N): " monitoring_complete

if [[ $monitoring_complete =~ ^[Yy]$ ]]; then
    echo ""
    echo "üéâ MONITORING SYSTEM SETUP COMPLETE!"
    echo "===================================="
    echo ""
    echo "‚úÖ Your {{PROJECT_NAME}} application now has:"
    echo "   üéØ Comprehensive automated monitoring"
    echo "   üö® Alert and notification systems"
    echo "   üîß Automated maintenance procedures"
    echo "   üíæ Backup verification and management"
    echo "   ‚ö° Performance tracking and optimization"
    echo "   üë§ Clear human task integration"
    echo ""
    echo "üîÑ Ongoing Operations:"
    echo "   - Monitoring runs automatically via GitHub Actions"
    echo "   - Weekly human verification recommended"
    echo "   - Monthly maintenance review suggested"
    echo "   - Emergency procedures documented and accessible"
    echo ""
    echo "üìä Monitor your system at:"
    echo "   üåê Applications: https://staging.{{DOMAIN}} & https://{{DOMAIN}}"
    echo "   üìã GitHub Actions: https://github.com/{{GITHUB_USERNAME}}/{{REPOSITORY_NAME}}/actions"
    echo "   üîß Emergency Guide: .github/scripts/human-task-manager.sh"

else
    echo ""
    echo "üìù Monitoring setup incomplete"
    echo "üìã Complete remaining tasks before considering setup finished"
    echo "üîß Use .github/scripts/human-task-manager.sh for guidance"
fi
```

**Expected Final State:**

-   Complete automated monitoring ecosystem operational
-   All workflows scheduled and executing automatically
-   Human integration points clearly defined and functional
-   Emergency procedures documented and accessible
-   Performance tracking and optimization systems active

---

## üìã **Next Steps and Ongoing Management**

### **Monitoring Dashboard and Management Guide**

```bash
echo ""
echo "üìä ONGOING MONITORING MANAGEMENT"
echo "==============================="
echo ""
echo "üéØ Daily Monitoring (Automated):"
echo "   - Health checks every 30 minutes"
echo "   - Backup verification daily"
echo "   - Automatic maintenance weekly"
echo ""
echo "üë§ Weekly Human Tasks:"
echo "   - Review GitHub Actions monitoring results"
echo "   - Test website functionality manually"
echo "   - Check performance metrics and alerts"
echo "   - Verify backup system status"
echo ""
echo "üîß Monthly Management Tasks:"
echo "   - Review monitoring thresholds and adjust if needed"
echo "   - Update alert contact information"
echo "   - Check for monitoring system improvements"
echo "   - Review performance trends and optimization opportunities"
echo ""
echo "üìä Key Monitoring URLs:"
echo "   üéØ GitHub Actions: https://github.com/{{GITHUB_USERNAME}}/{{REPOSITORY_NAME}}/actions"
echo "   üß™ Staging: https://staging.{{DOMAIN}}"
echo "   üöÄ Production: https://{{DOMAIN}}"
echo ""
echo "üîß Management Scripts:"
echo "   üìã Weekly tasks: bash .github/scripts/human-task-manager.sh"
echo "   üö® Alert setup: bash .github/scripts/alert-manager.sh"
echo "   üîß Emergency guide: Available in human-task-manager.sh"
```

**Expected Ongoing Activities:**

-   Automated monitoring provides continuous oversight
-   Human verification maintains operational awareness
-   Performance tracking enables proactive optimization
-   Emergency procedures ensure rapid issue resolution
-   Maintenance automation keeps system healthy

---

## üéØ **Key Success Indicators**

-   **Monitoring Active**: ‚úÖ All workflows running on schedule with health reporting
-   **Alert System**: üö® Configured notifications and emergency procedures operational
-   **Performance Tracking**: ‚ö° Weekly performance analysis and trend monitoring
-   **Maintenance Automation**: üßπ Automated cleanup and optimization procedures
-   **Human Integration**: üë§ Clear manual task identification and completion tracking
-   **Emergency Ready**: üö® Documented procedures and rapid response capabilities

**Comprehensive Automated Monitoring and Maintenance System fully operational!** üéâ

---

## üìã **Next Steps**

‚úÖ **Step 24B Complete** - Comprehensive monitoring and maintenance automation established  
üîÑ **Optional Enhancement**: Additional monitoring tools and integrations  
üéØ **Ongoing Operations**: Weekly human verification and monthly system review  
üìä **Continuous Improvement**: Regular monitoring system optimization and enhancement

**Scenario B complete with full automation, monitoring, and maintenance!** üöÄ

## ‚ö° Quick Reference

**Time Required**: ~30 minutes setup, ongoing monitoring  
**Prerequisites**: Step 23B completed successfully  
**Critical Path**: Monitoring setup ‚Üí Maintenance workflows ‚Üí Automated alerting ‚Üí Backup verification

---

## üîÑ **PHASE 1: Automated Health Monitoring Setup**

### **1.1 Create Health Monitoring Workflow**

```bash
# Create continuous monitoring workflow
cat > .github/workflows/health-monitor.yml << 'EOF'
name: Health Monitor

on:
  schedule:
    # Run health checks every 30 minutes
    - cron: '*/30 * * * *'
  workflow_dispatch: # Allow manual triggers

jobs:
  health-check:
    runs-on: ubuntu-latest

    steps:
    - name: üîç Health Check - Staging
      run: |
        echo "üß™ Checking staging environment..."
        STAGING_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 30 https://staging.societypal.com)
        STAGING_TIME=$(curl -w "%{time_total}" -s -o /dev/null https://staging.societypal.com)

        if [ "$STAGING_STATUS" = "200" ]; then
          echo "‚úÖ Staging: OK (HTTP $STAGING_STATUS, ${STAGING_TIME}s)"
        else
          echo "‚ùå Staging: ISSUE (HTTP $STAGING_STATUS)"
          echo "::warning::Staging environment health check failed"
        fi

    - name: üöÄ Health Check - Production
      run: |
        echo "üåê Checking production environment..."
        PROD_STATUS=$(curl -s -o /dev/null -w "%{http_code}" --max-time 30 https://societypal.com)
        PROD_TIME=$(curl -w "%{time_total}" -s -o /dev/null https://societypal.com)

        if [ "$PROD_STATUS" = "200" ]; then
          echo "‚úÖ Production: OK (HTTP $PROD_STATUS, ${PROD_TIME}s)"

          # Performance alert if response time > 3 seconds
          if (( $(echo "$PROD_TIME > 3.0" | bc -l) )); then
            echo "::warning::Production response time slow: ${PROD_TIME}s"
          fi
        else
          echo "‚ùå Production: CRITICAL (HTTP $PROD_STATUS)"
          echo "::error::Production environment health check failed"
        fi

    - name: üìä SSL Certificate Check
      run: |
        echo "üîí Checking SSL certificates..."

        # Check staging SSL
        STAGING_SSL=$(curl -vI https://staging.societypal.com 2>&1 | grep -E "SSL|TLS|certificate" | wc -l)
        if [ "$STAGING_SSL" -gt 0 ]; then
          echo "‚úÖ Staging SSL: Active"
        else
          echo "‚ö†Ô∏è Staging SSL: Check required"
        fi

        # Check production SSL
        PROD_SSL=$(curl -vI https://societypal.com 2>&1 | grep -E "SSL|TLS|certificate" | wc -l)
        if [ "$PROD_SSL" -gt 0 ]; then
          echo "‚úÖ Production SSL: Active"
        else
          echo "‚ùå Production SSL: ISSUE"
          echo "::error::Production SSL certificate problem"
        fi

    - name: üìà Performance Summary
      run: |
        echo "üìä Health Monitor Summary"
        echo "========================"
        echo "Timestamp: $(date -u)"
        echo "Staging: https://staging.societypal.com"
        echo "Production: https://societypal.com"
        echo ""
        echo "Next automated check: $(date -u -d '+30 minutes')"
EOF

echo "‚úÖ Health monitoring workflow created"
```

**Expected Result:**

-   Automated health checks every 30 minutes
-   Performance monitoring and alerting
-   SSL certificate verification
-   GitHub Actions warnings for issues

### **1.2 Create Backup Verification Workflow**

```bash
# Create backup verification workflow
cat > .github/workflows/backup-verify.yml << 'EOF'
name: Backup Verification

on:
  schedule:
    # Run backup verification daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  verify-backups:
    runs-on: ubuntu-latest

    steps:
    - name: üîë Setup SSH
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts

    - name: üìä Verify Backup Status
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üíæ Checking backup status..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üìã Backup Directory Status:"

          # Check backup directories exist
          if [ -d ~/backups/database ]; then
            DB_COUNT=$(ls ~/backups/database/*.sql.gz 2>/dev/null | wc -l)
            echo "‚úÖ Database backups: $DB_COUNT files"

            # Check recent backup (within 48 hours)
            RECENT_DB=$(find ~/backups/database -name "*.sql.gz" -mtime -2 | wc -l)
            if [ "$RECENT_DB" -gt 0 ]; then
              echo "‚úÖ Recent database backup: Available"
            else
              echo "‚ùå Recent database backup: MISSING"
            fi
          else
            echo "‚ùå Database backup directory: MISSING"
          fi

          # Check file backups
          if [ -d ~/backups/files ]; then
            FILE_COUNT=$(ls ~/backups/files/*.tar.gz 2>/dev/null | wc -l)
            echo "‚úÖ File backups: $FILE_COUNT archives"

            RECENT_FILES=$(find ~/backups/files -name "*.tar.gz" -mtime -2 | wc -l)
            if [ "$RECENT_FILES" -gt 0 ]; then
              echo "‚úÖ Recent file backup: Available"
            else
              echo "‚ùå Recent file backup: MISSING"
            fi
          else
            echo "‚ùå File backup directory: MISSING"
          fi

          # Check disk space
          echo ""
          echo "üíæ Disk Space Status:"
          df -h ~/backups/ ~/domains/ | head -3

          # Alert if disk usage > 80%
          DISK_USAGE=$(df ~/domains/ | tail -1 | awk '{print $5}' | sed 's/%//')
          if [ "$DISK_USAGE" -gt 80 ]; then
            echo "‚ö†Ô∏è Disk usage high: ${DISK_USAGE}%"
          else
            echo "‚úÖ Disk usage normal: ${DISK_USAGE}%"
          fi
        ENDSSH

    - name: üìß Backup Alert Summary
      run: |
        echo "üìä Backup Verification Complete"
        echo "==============================="
        echo "Daily backup verification completed"
        echo "Check logs above for any issues"
        echo "Manual intervention required if backups missing"
EOF

echo "‚úÖ Backup verification workflow created"
```

**Expected Result:**

-   Daily automated backup verification
-   Disk space monitoring
-   Alert generation for missing backups
-   Automated backup health reporting

---

## üîÑ **PHASE 2: Maintenance Workflow Automation**

### **2.1 Create Dependency Update Workflow**

````bash
# Create automated dependency update workflow
cat > .github/workflows/dependency-updates.yml << 'EOF'
name: Dependency Updates

on:
  schedule:
    # Run monthly on first day at 1 AM UTC
    - cron: '0 1 1 * *'
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Update type'
        required: true
        default: 'patch'
        type: choice
        options:
        - patch
        - minor
        - major

jobs:
  update-dependencies:
    runs-on: ubuntu-latest

    steps:
    - name: üì• Checkout Code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: üêò Setup PHP
      uses: shivammathur/setup-php@v2
      with:
        php-version: '8.2'
        extensions: mbstring, xml, ctype, iconv, intl, pdo_mysql, zip, curl
        coverage: none
        tools: composer:v2

    - name: üì¶ Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'

    - name: üîç Check Current Dependencies
      run: |
        echo "üìã Current PHP Dependencies:"
        composer show --outdated | head -10 || echo "All packages up to date"

        echo ""
        echo "üìã Current Node Dependencies:"
        if [ -f "package.json" ]; then
          npm outdated | head -10 || echo "All packages up to date"
        fi

    - name: üîÑ Update Dependencies
      run: |
        UPDATE_TYPE="${{ github.event.inputs.update_type || 'patch' }}"
        echo "üîÑ Performing $UPDATE_TYPE updates..."

        # PHP dependency updates
        case "$UPDATE_TYPE" in
          "patch")
            composer update --with-dependencies --prefer-stable --no-interaction
            ;;
          "minor")
            composer update --with-dependencies --prefer-stable --no-interaction
            ;;
          "major")
            echo "‚ö†Ô∏è Major updates require manual review"
            composer show --outdated
            ;;
        esac

        # Node dependency updates (if package.json exists)
        if [ -f "package.json" ]; then
          case "$UPDATE_TYPE" in
            "patch")
              npm update
              ;;
            "minor")
              npm update
              ;;
            "major")
              echo "‚ö†Ô∏è Major Node updates require manual review"
              npm outdated
              ;;
          esac
        fi

    - name: üß™ Test Updated Dependencies
      run: |
        echo "üß™ Testing updated dependencies..."

        # Test PHP autoload
        composer dump-autoload --optimize

        # Test Laravel configuration
        cp .env.example .env
        php artisan key:generate
        php artisan config:cache
        php artisan route:cache
        php artisan view:cache

        # Test frontend build (if applicable)
        if [ -f "package.json" ]; then
          npm ci --only=production
          npm run build
        fi

        echo "‚úÖ Dependency testing completed"

    - name: üìù Create Update Report
      run: |
        echo "üìù Creating dependency update report..."

        cat > dependency-update-report.md << 'REPORT'
        # Dependency Update Report

        **Date:** $(date -u)
        **Update Type:** ${{ github.event.inputs.update_type || 'patch' }}
        **Branch:** ${{ github.ref_name }}

        ## Updated Packages

        ### PHP Dependencies
        ```
        $(composer show --installed | grep -E "laravel|symfony" | head -10)
        ```

        ### Node Dependencies
        ```
        $(if [ -f "package.json" ]; then npm list --depth=0 | head -10; else echo "No Node dependencies"; fi)
        ```

        ## Testing Status
        - ‚úÖ PHP autoload generation
        - ‚úÖ Laravel optimization
        - ‚úÖ Frontend build (if applicable)

        ## Next Steps
        1. Review changes in staging environment
        2. Run full test suite
        3. Deploy to staging for validation
        4. Deploy to production after testing

        REPORT

    - name: üíæ Commit Updates
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        if git diff --quiet; then
          echo "‚ÑπÔ∏è No dependency updates available"
        else
          git add composer.lock package-lock.json 2>/dev/null || true
          git commit -m "chore: update dependencies (${{ github.event.inputs.update_type || 'patch' }})

          - Automated dependency updates
          - Tested configurations and builds
          - Ready for staging deployment"

          echo "‚úÖ Dependency updates committed"
          echo "üöÄ Push to trigger staging deployment for testing"
        fi
EOF

echo "‚úÖ Dependency update workflow created"
````

**Expected Result:**

-   Monthly automated dependency updates
-   Patch/minor/major update options
-   Automated testing of updates
-   Report generation for review

### **2.2 Create Release Management Workflow**

```bash
# Create release management workflow
cat > .github/workflows/release-management.yml << 'EOF'
name: Release Management

on:
  workflow_dispatch:
    inputs:
      release_type:
        description: 'Release type'
        required: true
        default: 'patch'
        type: choice
        options:
        - patch
        - minor
        - major
      release_notes:
        description: 'Release notes'
        required: false
        default: 'Automated release'

jobs:
  create-release:
    runs-on: ubuntu-latest

    steps:
    - name: üì• Checkout Code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: üè∑Ô∏è Generate Version Number
      id: version
      run: |
        # Get latest tag
        LATEST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "v0.0.0")
        echo "Latest tag: $LATEST_TAG"

        # Parse version numbers
        VERSION=${LATEST_TAG#v}
        IFS='.' read -ra VERSION_PARTS <<< "$VERSION"
        MAJOR=${VERSION_PARTS[0]:-0}
        MINOR=${VERSION_PARTS[1]:-0}
        PATCH=${VERSION_PARTS[2]:-0}

        # Increment based on release type
        case "${{ github.event.inputs.release_type }}" in
          "major")
            MAJOR=$((MAJOR + 1))
            MINOR=0
            PATCH=0
            ;;
          "minor")
            MINOR=$((MINOR + 1))
            PATCH=0
            ;;
          "patch")
            PATCH=$((PATCH + 1))
            ;;
        esac

        NEW_VERSION="v${MAJOR}.${MINOR}.${PATCH}"
        echo "New version: $NEW_VERSION"
        echo "version=$NEW_VERSION" >> $GITHUB_OUTPUT

    - name: üìù Generate Release Notes
      id: release_notes
      run: |
        echo "üìù Generating release notes for ${{ steps.version.outputs.version }}"

        # Get commits since last tag
        LATEST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "")
        if [ -n "$LATEST_TAG" ]; then
          COMMITS=$(git log ${LATEST_TAG}..HEAD --oneline --pretty=format:"- %s")
        else
          COMMITS=$(git log --oneline --pretty=format:"- %s" | head -10)
        fi

        # Create release notes
        cat > release_notes.md << NOTES
        # Release ${{ steps.version.outputs.version }}

        **Release Date:** $(date -u +"%Y-%m-%d")
        **Release Type:** ${{ github.event.inputs.release_type }}

        ## Changes in this Release

        ${{ github.event.inputs.release_notes }}

        ## Commits

        $COMMITS

        ## Deployment Information

        - **Staging:** https://staging.societypal.com
        - **Production:** https://societypal.com
        - **Deployment Method:** GitHub Actions (Scenario B)

        ## Verification Steps

        1. ‚úÖ All GitHub Actions workflows passing
        2. ‚úÖ Staging environment tested
        3. ‚úÖ Database migrations completed
        4. ‚úÖ Performance benchmarks met

        NOTES

    - name: üè∑Ô∏è Create Git Tag
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        git tag -a ${{ steps.version.outputs.version }} -m "Release ${{ steps.version.outputs.version }}

        ${{ github.event.inputs.release_notes }}

        Release type: ${{ github.event.inputs.release_type }}
        Generated: $(date -u)"

        git push origin ${{ steps.version.outputs.version }}
        echo "‚úÖ Tag ${{ steps.version.outputs.version }} created and pushed"

    - name: üì¶ Create GitHub Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ steps.version.outputs.version }}
        release_name: Release ${{ steps.version.outputs.version }}
        body_path: release_notes.md
        draft: false
        prerelease: false

    - name: üöÄ Trigger Production Deployment
      run: |
        echo "üöÄ Release ${{ steps.version.outputs.version }} created"
        echo "üìã Next steps:"
        echo "1. Merge to production branch: git checkout production && git merge ${{ github.ref_name }}"
        echo "2. Push to trigger deployment: git push origin production"
        echo "3. Monitor deployment in GitHub Actions"
        echo "4. Verify at: https://societypal.com"
EOF

echo "‚úÖ Release management workflow created"
```

**Expected Result:**

-   Automated version numbering
-   Release notes generation
-   Git tagging and GitHub releases
-   Production deployment guidance

---

## üîÑ **PHASE 3: Server-Side Monitoring Setup**

### **3.1 Create Server Monitoring Scripts**

```bash
# Create comprehensive server monitoring
cat > .github/scripts/server-monitor.sh << 'EOF'
#!/bin/bash

# Server monitoring script for SocietyPal deployment

echo "üñ•Ô∏è SocietyPal Server Health Monitor"
echo "=================================="
echo "Timestamp: $(date)"
echo ""

# Function to check domain health
check_domain_health() {
    local domain=$1
    local domain_path="~/domains/$domain"

    echo "üåê Checking $domain:"
    echo "-------------------"

    # Check if domain directory exists
    if [ -d "$domain_path" ]; then
        echo "‚úÖ Domain directory: EXISTS"

        # Check current symlink
        if [ -L "$domain_path/current" ]; then
            CURRENT_RELEASE=$(readlink "$domain_path/current")
            echo "‚úÖ Current release: $CURRENT_RELEASE"
        else
            echo "‚ùå Current symlink: MISSING"
        fi

        # Check public_html symlink
        if [ -L "$domain_path/public_html" ]; then
            echo "‚úÖ Public symlink: EXISTS"
        else
            echo "‚ùå Public symlink: MISSING"
        fi

        # Check shared directories
        if [ -d "$domain_path/shared" ]; then
            echo "‚úÖ Shared directory: EXISTS"
            echo "   - Storage: $([ -d "$domain_path/shared/storage" ] && echo "EXISTS" || echo "MISSING")"
            echo "   - Environment: $([ -f "$domain_path/shared/.env" ] && echo "EXISTS" || echo "MISSING")"
        else
            echo "‚ùå Shared directory: MISSING"
        fi

        # Check release count
        if [ -d "$domain_path/releases" ]; then
            RELEASE_COUNT=$(ls "$domain_path/releases" | wc -l)
            echo "üì¶ Releases: $RELEASE_COUNT stored"

            # Show recent releases
            echo "   Recent releases:"
            ls -t "$domain_path/releases" | head -3 | sed 's/^/   - /'
        fi

        # Check Laravel application health
        if [ -f "$domain_path/current/artisan" ]; then
            echo "‚úÖ Laravel: DETECTED"

            # Check Laravel logs
            if [ -f "$domain_path/current/storage/logs/laravel.log" ]; then
                RECENT_ERRORS=$(grep -i "error\|exception\|fatal" "$domain_path/current/storage/logs/laravel.log" | tail -5 | wc -l)
                if [ "$RECENT_ERRORS" -gt 0 ]; then
                    echo "‚ö†Ô∏è Recent errors: $RECENT_ERRORS found"
                else
                    echo "‚úÖ Error log: CLEAN"
                fi
            fi
        fi

    else
        echo "‚ùå Domain directory: NOT FOUND"
    fi
    echo ""
}

# Check both environments
check_domain_health "staging.societypal.com"
check_domain_health "societypal.com"

# Check disk usage
echo "üíæ Disk Usage:"
echo "-------------"
df -h ~/domains/ ~/backups/ | head -3

# Check system resources
echo ""
echo "üîß System Resources:"
echo "-------------------"
echo "Memory usage: $(free -h | grep '^Mem:' | awk '{print $3 "/" $2}')"
echo "Load average: $(uptime | awk -F'load average:' '{print $2}')"

# Check backup status
echo ""
echo "üíæ Backup Status:"
echo "----------------"
if [ -d ~/backups/database ]; then
    DB_BACKUP_COUNT=$(ls ~/backups/database/*.sql.gz 2>/dev/null | wc -l)
    echo "Database backups: $DB_BACKUP_COUNT files"

    LATEST_DB_BACKUP=$(ls -t ~/backups/database/*.sql.gz 2>/dev/null | head -1)
    if [ -n "$LATEST_DB_BACKUP" ]; then
        BACKUP_AGE=$(stat -c %Y "$LATEST_DB_BACKUP")
        CURRENT_TIME=$(date +%s)
        AGE_HOURS=$(( (CURRENT_TIME - BACKUP_AGE) / 3600 ))
        echo "Latest database backup: ${AGE_HOURS}h ago"
    fi
else
    echo "‚ùå Database backup directory: NOT FOUND"
fi

# Check file backups
if [ -d ~/backups/files ]; then
    FILE_BACKUP_COUNT=$(ls ~/backups/files/*.tar.gz 2>/dev/null | wc -l)
    echo "File backups: $FILE_BACKUP_COUNT archives"
else
    echo "‚ùå File backup directory: NOT FOUND"
fi

echo ""
echo "‚úÖ Server monitoring completed"
echo "Next check recommended: $(date -d '+1 hour')"
EOF

chmod +x .github/scripts/server-monitor.sh
echo "‚úÖ Server monitoring script created"
```

### **3.2 Setup Automated Server Monitoring**

```bash
# Create server monitoring workflow
cat > .github/workflows/server-monitor.yml << 'EOF'
name: Server Monitor

on:
  schedule:
    # Run server monitoring every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:

jobs:
  monitor-server:
    runs-on: ubuntu-latest

    steps:
    - name: üì• Checkout Code
      uses: actions/checkout@v4

    - name: üîë Setup SSH
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts

    - name: üñ•Ô∏è Run Server Health Check
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üñ•Ô∏è Running comprehensive server health check..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST 'bash -s' < .github/scripts/server-monitor.sh

    - name: üìä Performance Metrics
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üìä Collecting performance metrics..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "‚ö° Application Performance:"
          echo "=========================="

          # Check Laravel queue status
          if [ -f ~/domains/societypal.com/current/artisan ]; then
            cd ~/domains/societypal.com/current
            echo "Queue workers: $(pgrep -f "queue:work" | wc -l)"
            echo "Failed jobs: $(php artisan queue:failed --format=json 2>/dev/null | jq '. | length' 2>/dev/null || echo "N/A")"
          fi

          # Check database connections
          MYSQL_CONNECTIONS=$(mysqladmin processlist 2>/dev/null | wc -l || echo "N/A")
          echo "MySQL connections: $MYSQL_CONNECTIONS"

          # Check web server status
          if pgrep nginx > /dev/null; then
            echo "‚úÖ Nginx: RUNNING"
          else
            echo "‚ùå Nginx: NOT RUNNING"
          fi

          if pgrep php-fpm > /dev/null; then
            echo "‚úÖ PHP-FPM: RUNNING"
          else
            echo "‚ùå PHP-FPM: NOT RUNNING"
          fi
        ENDSSH

    - name: üìà Generate Health Report
      run: |
        echo "üìà Server Health Report Summary"
        echo "==============================="
        echo "Monitor completed at: $(date -u)"
        echo "Next scheduled check: $(date -u -d '+4 hours')"
        echo ""
        echo "üéØ Key Metrics to Review:"
        echo "- Domain accessibility"
        echo "- Release deployment status"
        echo "- Backup freshness"
        echo "- Resource utilization"
        echo "- Service status"
        echo ""
        echo "üîç Manual investigation required if:"
        echo "- Any domain shows errors"
        echo "- Backups older than 48 hours"
        echo "- Disk usage above 80%"
        echo "- Services not running"
EOF

echo "‚úÖ Server monitoring workflow created"
```

**Expected Result:**

-   Automated server health monitoring every 4 hours
-   Comprehensive application status checking
-   Performance metrics collection
-   Alert generation for issues

---

## üîÑ **PHASE 4: Performance Optimization Workflows**

### **4.1 Create Performance Testing Workflow**

```bash
# Create performance testing workflow
cat > .github/workflows/performance-test.yml << 'EOF'
name: Performance Test

on:
  schedule:
    # Run performance tests weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      test_environment:
        description: 'Test environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production

jobs:
  performance-test:
    runs-on: ubuntu-latest

    steps:
    - name: üéØ Setup Test Environment
      run: |
        TEST_ENV="${{ github.event.inputs.test_environment || 'staging' }}"

        if [ "$TEST_ENV" = "production" ]; then
          TEST_URL="https://societypal.com"
          echo "üöÄ Testing PRODUCTION environment"
        else
          TEST_URL="https://staging.societypal.com"
          echo "üß™ Testing STAGING environment"
        fi

        echo "TEST_URL=$TEST_URL" >> $GITHUB_ENV
        echo "TEST_ENV=$TEST_ENV" >> $GITHUB_ENV

    - name: ‚ö° Basic Performance Test
      run: |
        echo "‚ö° Running basic performance tests for $TEST_ENV..."
        echo "Target: $TEST_URL"
        echo ""

        # Test homepage performance
        echo "üè† Homepage Performance:"
        HOMEPAGE_TIME=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL")
        echo "   Response time: ${HOMEPAGE_TIME}s"

        if (( $(echo "$HOMEPAGE_TIME < 2.0" | bc -l) )); then
          echo "   ‚úÖ Performance: EXCELLENT"
        elif (( $(echo "$HOMEPAGE_TIME < 3.0" | bc -l) )); then
          echo "   ‚úÖ Performance: GOOD"
        else
          echo "   ‚ö†Ô∏è Performance: NEEDS OPTIMIZATION"
        fi

        # Test common routes
        echo ""
        echo "üõ£Ô∏è Route Performance Tests:"

        for route in "/login" "/register" "/dashboard"; do
          ROUTE_TIME=$(curl -w "%{time_total}" -s -o /dev/null "$TEST_URL$route" 2>/dev/null || echo "timeout")
          ROUTE_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$TEST_URL$route" 2>/dev/null || echo "000")
          echo "   $route: HTTP $ROUTE_STATUS (${ROUTE_TIME}s)"
        done

    - name: üîç Detailed Analysis
      run: |
        echo "üîç Detailed performance analysis..."
        echo ""

        # Analyze response headers
        echo "üìã Response Headers Analysis:"
        curl -I "$TEST_URL" | grep -E "Server|Cache|Content-Type|Content-Encoding"

        echo ""
        echo "üóúÔ∏è Compression Test:"
        COMPRESSED_SIZE=$(curl -H "Accept-Encoding: gzip" -s "$TEST_URL" | wc -c)
        UNCOMPRESSED_SIZE=$(curl -s "$TEST_URL" | wc -c)

        if [ "$COMPRESSED_SIZE" -lt "$UNCOMPRESSED_SIZE" ]; then
          COMPRESSION_RATIO=$(( (UNCOMPRESSED_SIZE - COMPRESSED_SIZE) * 100 / UNCOMPRESSED_SIZE ))
          echo "   ‚úÖ Compression active: ${COMPRESSION_RATIO}% savings"
        else
          echo "   ‚ö†Ô∏è Compression: NOT DETECTED"
        fi

        echo ""
        echo "üîí Security Headers Check:"
        SECURITY_HEADERS=$(curl -I "$TEST_URL" | grep -E "X-Frame-Options|X-Content-Type-Options|Strict-Transport-Security" | wc -l)
        echo "   Security headers found: $SECURITY_HEADERS"

    - name: üìä Performance Report
      run: |
        echo "üìä Performance Test Summary"
        echo "=========================="
        echo "Environment: $TEST_ENV"
        echo "URL: $TEST_URL"
        echo "Test Date: $(date -u)"
        echo ""
        echo "üéØ Performance Targets:"
        echo "   Homepage: < 2.0s (Excellent), < 3.0s (Good)"
        echo "   Routes: < 2.0s for authenticated pages"
        echo "   Compression: Should be active"
        echo "   Security: Headers should be present"
        echo ""
        echo "üìà Recommendations:"
        echo "   - Monitor response times weekly"
        echo "   - Optimize if performance degrades"
        echo "   - Enable compression if not active"
        echo "   - Implement security headers if missing"
        echo ""
        echo "üîÑ Next test: $(date -u -d '+1 week')"
EOF

echo "‚úÖ Performance testing workflow created"
```

**Expected Result:**

-   Weekly automated performance testing
-   Response time monitoring
-   Compression and security analysis
-   Performance trend tracking

### **4.2 Create Database Maintenance Workflow**

```bash
# Create database maintenance workflow
cat > .github/workflows/database-maintenance.yml << 'EOF'
name: Database Maintenance

on:
  schedule:
    # Run database maintenance weekly on Saturdays at 2 AM UTC
    - cron: '0 2 * * 6'
  workflow_dispatch:

jobs:
  database-maintenance:
    runs-on: ubuntu-latest

    steps:
    - name: üîë Setup SSH
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
        SERVER_SSH_KEY: ${{ secrets.SERVER_SSH_KEY }}
      run: |
        mkdir -p ~/.ssh
        echo "$SERVER_SSH_KEY" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        ssh-keyscan -p $SERVER_PORT $SERVER_HOST >> ~/.ssh/known_hosts

    - name: üóÑÔ∏è Database Health Check
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üóÑÔ∏è Running database health check..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          echo "üìä Database Health Analysis"
          echo "=========================="

          # Check database connections
          cd ~/domains/societypal.com/current

          echo "üîó Connection Test:"
          if php artisan tinker --execute="DB::connection()->getPdo(); echo 'Database: CONNECTED';" 2>/dev/null; then
            echo "‚úÖ Database connection: OK"
          else
            echo "‚ùå Database connection: FAILED"
          fi

          echo ""
          echo "üìã Migration Status:"
          php artisan migrate:status | head -10

          echo ""
          echo "üìä Database Size Analysis:"
          mysql -e "
            SELECT
              table_schema as 'Database',
              ROUND(SUM(data_length + index_length) / 1024 / 1024, 2) AS 'Size (MB)'
            FROM information_schema.tables
            WHERE table_schema = DATABASE()
            GROUP BY table_schema;
          " 2>/dev/null || echo "Database size query failed"

          echo ""
          echo "üßπ Table Analysis:"
          mysql -e "
            SELECT
              table_name as 'Table',
              table_rows as 'Rows',
              ROUND((data_length + index_length) / 1024 / 1024, 2) AS 'Size (MB)'
            FROM information_schema.tables
            WHERE table_schema = DATABASE()
            ORDER BY (data_length + index_length) DESC
            LIMIT 10;
          " 2>/dev/null || echo "Table analysis query failed"
        ENDSSH

    - name: üíæ Create Database Backup
      env:
        SERVER_HOST: ${{ secrets.SERVER_HOST }}
        SERVER_USER: ${{ secrets.SERVER_USER }}
        SERVER_PORT: ${{ secrets.SERVER_PORT }}
      run: |
        echo "üíæ Creating database backup..."

        ssh -p $SERVER_PORT -i ~/.ssh/deploy_key $SERVER_USER@$SERVER_HOST << 'ENDSSH'
          # Create backup with timestamp
          BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
          mkdir -p ~/backups/database

          echo "üì¶ Creating backup: backup_${BACKUP_DATE}.sql"

          # Get database credentials from .env
          cd ~/domains/societypal.com/current
          DB_NAME=$(grep DB_DATABASE .env | cut -d '=' -f2)
          DB_USER=$(grep DB_USERNAME .env | cut -d '=' -f2)
          DB_PASS=$(grep DB_PASSWORD .env | cut -d '=' -f2)

          if [ -n "$DB_NAME" ] && [ -n "$DB_USER" ] && [ -n "$DB_PASS" ]; then
            # Create database backup
            mysqldump -u "$DB_USER" -p"$DB_PASS" "$DB_NAME" > ~/backups/database/backup_${BACKUP_DATE}.sql

            # Compress backup
            gzip ~/backups/database/backup_${BACKUP_DATE}.sql

            echo "‚úÖ Backup created: backup_${BACKUP_DATE}.sql.gz"

            # Show backup size
            du -h ~/backups/database/backup_${BACKUP_DATE}.sql.gz

            # Cleanup old backups (keep last 10)
            cd ~/backups/database
            ls -t *.sql.gz | tail -n +11 | xargs rm -f 2>/dev/null || true
            echo "üßπ Cleaned up old backups"

          else
            echo "‚ùå Database credentials not found in .env"
          fi
        ENDSSH

    - name: üìà Maintenance Summary
      run: |
        echo "üìà Database Maintenance Summary"
        echo "=============================="
        echo "Maintenance completed: $(date -u)"
        echo ""
        echo "‚úÖ Tasks Completed:"
        echo "   - Database health check"
        echo "   - Connection verification"
        echo "   - Migration status review"
        echo "   - Size analysis"
        echo "   - Backup creation"
        echo "   - Backup cleanup"
        echo ""
        echo "üîÑ Next maintenance: $(date -u -d '+1 week')"
        echo ""
        echo "‚ö†Ô∏è Manual attention required if:"
        echo "   - Database connection failures"
        echo "   - Pending migrations"
        echo "   - Excessive database growth"
        echo "   - Backup creation failures"
EOF

echo "‚úÖ Database maintenance workflow created"
```

**Expected Result:**

-   Weekly automated database maintenance
-   Health monitoring and backup creation
-   Size analysis and optimization alerts
-   Automated cleanup of old backups

---

## ‚úÖ **Success Verification and Final Setup**

### **Workflow Configuration Summary**

```bash
# Verify all monitoring workflows are created
echo "üìã GitHub Actions Monitoring Workflows Summary"
echo "=============================================="
echo ""
echo "‚úÖ Created Workflows:"
ls -la .github/workflows/
echo ""
echo "‚úÖ Created Scripts:"
ls -la .github/scripts/
echo ""
echo "üìä Monitoring Schedule:"
echo "   - Health checks: Every 30 minutes"
echo "   - Backup verification: Daily at 2 AM UTC"
echo "   - Dependency updates: Monthly"
echo "   - Server monitoring: Every 4 hours"
echo "   - Performance tests: Weekly (Sundays)"
echo "   - Database maintenance: Weekly (Saturdays)"
echo ""
echo "üéØ Manual Setup Required:"
echo "   1. Commit all workflow files to repository"
echo "   2. Verify GitHub secrets are configured"
echo "   3. Test manual workflow triggers"
echo "   4. Monitor first automated runs"
```

### **Commit All Monitoring Files**

```bash
# Add all monitoring and maintenance files
git add .github/workflows/
git add .github/scripts/
git add .github/DEPLOYMENT_SECRETS.md

# Commit monitoring setup
git commit -m "feat: add comprehensive monitoring and maintenance workflows

- Health monitoring every 30 minutes with alerting
- Daily backup verification and reporting
- Monthly dependency updates with testing
- Server monitoring every 4 hours
- Weekly performance testing and analysis
- Database maintenance and backup automation
- Release management with version control
- Comprehensive documentation and scripts"

echo "‚úÖ All monitoring workflows committed"
echo ""
echo "üöÄ Next steps:"
echo "1. Push to repository: git push origin main"
echo "2. Verify workflows appear in GitHub Actions"
echo "3. Test manual workflow triggers"
echo "4. Monitor automated executions"
```

**Expected Final State:**

-   Complete monitoring automation in place
-   All workflows scheduled and ready
-   Comprehensive health checking active
-   Automated maintenance procedures established

---

## üìã **Next Steps and Ongoing Management**

### **Monitoring Dashboard Setup**

```bash
echo "üìä Monitoring Management Guide"
echo "============================="
echo ""
echo "GitHub Actions Monitoring:"
echo "   ‚Üí Repository ‚Üí Actions tab"
echo "   ‚Üí Monitor workflow success/failure"
echo "   ‚Üí Review logs for issues"
echo ""
echo "Manual Workflow Triggers:"
echo "   ‚Üí Actions ‚Üí Select workflow ‚Üí Run workflow"
echo "   ‚Üí Test dependency updates"
echo "   ‚Üí Trigger performance tests"
echo "   ‚Üí Create releases"
echo ""
echo "Key Metrics to Monitor:"
echo "   - Deployment success rate"
echo "   - Performance trends"
echo "   - Backup freshness"
echo "   - Security status"
echo "   - Resource utilization"
echo ""
echo "Alert Thresholds:"
echo "   - Response time > 3 seconds"
echo "   - Backup age > 48 hours"
echo "   - Disk usage > 80%"
echo "   - Service failures"
```

**Expected Ongoing Activities:**

-   Daily review of monitoring alerts
-   Weekly performance trend analysis
-   Monthly dependency update reviews
-   Quarterly security audits
-   As-needed manual interventions

---

## üéØ **Key Success Indicators**

-   **Monitoring Active**: ‚úÖ All workflows running on schedule
-   **Health Checking**: üìä Automated verification every 30 minutes
-   **Backup Verification**: üíæ Daily backup status confirmation
-   **Performance Tracking**: ‚ö° Weekly performance analysis
-   **Maintenance Automation**: üîß Server and database maintenance
-   **Alert System**: üö® GitHub Actions warnings for issues
-   **Release Management**: üì¶ Automated version control and releases

**Scenario B monitoring and maintenance system fully operational!** üéâ

---

## üìã **Next Steps**

‚úÖ **Step 24B Complete** - Comprehensive monitoring and maintenance automation established  
üîÑ **Continue to**: Scenario C deployment setup (if needed)  
üéØ **Ongoing**: Monitor GitHub Actions for automated health checks and maintenance  
üìä **Optional**: Set up external monitoring tools for additional redundancy

**Scenario B complete with full automation and monitoring!** üöÄ
